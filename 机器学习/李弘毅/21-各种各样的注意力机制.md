![img_128.png](img_128.png)

![img_129.png](img_129.png)

### local attention/truncated attention(比如: 邻居attention)
### stride attention
![img_130.png](img_130.png)
### global attention
![img_131.png](img_131.png)
![img_132.png](img_132.png)


### Longformer Big Bird
![img_133.png](img_133.png)

![img_134.png](img_134.png)

### Clustering 技术(Reformer and Routing Transformer)
![img_135.png](img_135.png)
![img_136.png](img_136.png)

### Learnable patterns(sinkhorn sorting network)
![img_137.png](img_137.png)
![img_138.png](img_138.png)

![img_139.png](img_139.png)

### Linformer
![img_140.png](img_140.png)
![img_141.png](img_141.png)

![img_142.png](img_142.png)

![img_143.png](img_143.png)

![img_144.png](img_144.png)

#### Compressed attention(有代表性的key)
![img_145.png](img_145.png)


#### attention mechanism is three-matrix multiplication
![img_146.png](img_146.png)

![img_147.png](img_147.png)

![img_148.png](img_148.png)

![img_149.png](img_149.png)

![img_150.png](img_150.png)

![img_151.png](img_151.png)

![img_152.png](img_152.png)

![img_153.png](img_153.png)

![img_154.png](img_154.png)

![img_155.png](img_155.png)

![img_156.png](img_156.png)
![img_157.png](img_157.png)

![img_158.png](img_158.png)


![img_159.png](img_159.png)



### Realization
![img_160.png](img_160.png)

### Synthesizer

![img_161.png](img_161.png)

![img_162.png](img_162.png)


![img_163.png](img_163.png)



![img_164.png](img_164.png)

