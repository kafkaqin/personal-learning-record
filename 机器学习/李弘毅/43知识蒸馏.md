# 有三大模型压缩的方法
1. 剪枝
2. 知识蒸馏
3. 参数量化

## Knowledge Distillation(知识蒸馏)
![img_323.png](img_323.png)

#### Ensemble集成学习
1. Bagging 装袋法
2. Boosting(提升法)
3. Stacking(迭代法)

#### Temperature for softmax
![img_324.png](img_324.png)

## 参数量化
1. Using less bits to represent a value
2. Weight clustering
3. Represent frequent clusters by less bits 
4. Binary Weight 二值量化
![img_325.png](img_325.png)

#### 回顾CNN
![img_326.png](img_326.png)

#### 深度可分分离卷积（Depthwise Separable Convolution）
1. 深度卷积 depthwise Convolution
2. 逐点卷积 pointwise Convolution

![img_328.png](img_328.png)
![img_327.png](img_327.png)

![img_329.png](img_329.png)

#### Low Rank approximation(低秩近似)
![img_330.png](img_330.png)
![img_331.png](img_331.png)
![img_332.png](img_332.png)

## Dynamic Computation(动态计算)
1. The network adjusts the computation it needed
2. Dynamic Depth 动态调整深度
![img_333.png](img_333.png)
3. Dynamic Width 动态调整宽度
![img_334.png](img_334.png)
4. 基于样本难度的计算(Computation based on Sample Difficulty)
![img_335.png](img_335.png)

### 总结
![img_336.png](img_336.png)


