å®ç°ä¸€ä¸ª**è¿›é˜¶ GAN æ¨¡å‹ï¼ˆå¦‚ StyleGANï¼‰** æ˜¯æ·±åº¦å­¦ä¹ ä¸­éå¸¸å…·æœ‰æŒ‘æˆ˜æ€§ä½†æå…·ä»·å€¼çš„ä»»åŠ¡ã€‚StyleGAN ç”± NVIDIA æå‡ºï¼Œæ˜¯ç”Ÿæˆé«˜è´¨é‡ã€é«˜åˆ†è¾¨ç‡äººè„¸å›¾åƒçš„é‡Œç¨‹ç¢‘å¼æ¨¡å‹ã€‚å®ƒé€šè¿‡å¼•å…¥ **é£æ ¼è¿ç§»ï¼ˆStyle-Based Generatorï¼‰** å’Œ **è·¯å¾„æ­£åˆ™åŒ–ï¼ˆPath Length Regularizationï¼‰** ç­‰æœºåˆ¶ï¼Œå®ç°äº†å‰æ‰€æœªæœ‰çš„å›¾åƒç”Ÿæˆè´¨é‡ã€‚

ç”±äºå®Œæ•´å®ç° StyleGAN éå¸¸å¤æ‚ï¼ˆæ¶‰åŠæ•°åƒè¡Œä»£ç å’Œå¤§é‡è®­ç»ƒèµ„æºï¼‰ï¼Œä¸‹é¢æˆ‘å°†ä¸ºä½ æä¾›ï¼š

1. âœ… **StyleGAN çš„æ ¸å¿ƒæ€æƒ³è§£æ**
2. âœ… **ä½¿ç”¨ `pytorch` å®ç°ä¸€ä¸ªç®€åŒ–ç‰ˆ StyleGAN çš„ Generator å’Œ Discriminator**
3. âœ… **å¦‚ä½•ä½¿ç”¨é¢„è®­ç»ƒçš„ StyleGAN æ¨¡å‹è¿›è¡Œå›¾åƒç”Ÿæˆï¼ˆæ¨èåˆå­¦è€…ï¼‰**
4. âœ… **è®­ç»ƒå»ºè®®ä¸èµ„æºé“¾æ¥**

---

## ğŸ§  ä¸€ã€StyleGAN æ ¸å¿ƒæ€æƒ³

### 1. ä¼ ç»Ÿ GAN çš„é—®é¢˜
- è¾“å…¥å™ªå£° z ç›´æ¥æ˜ å°„åˆ°å›¾åƒï¼Œæ§åˆ¶ç²’åº¦ç²—ã€‚
- å¾ˆéš¾ç‹¬ç«‹æ§åˆ¶å›¾åƒçš„â€œå§¿æ€â€ã€â€œçº¹ç†â€ã€â€œé¢œè‰²â€ç­‰ä¸åŒå±‚æ¬¡ç‰¹å¾ã€‚

### 2. StyleGAN çš„åˆ›æ–°

| æ¨¡å— | åŠŸèƒ½ |
|------|------|
| **Mapping Network** | å°†è¾“å…¥å™ªå£° z æ˜ å°„åˆ°ä¸­é—´æ½œåœ¨ç©ºé—´ Wï¼Œç”¨äºé£æ ¼æ§åˆ¶ |
| **AdaINï¼ˆAdaptive Instance Normalizationï¼‰** | å°†é£æ ¼å‘é‡æ³¨å…¥ç”Ÿæˆå™¨çš„æ¯ä¸ªå±‚çº§ |
| **Style Blocks** | æ¯ä¸€å±‚å¯ç‹¬ç«‹æ§åˆ¶å›¾åƒçš„â€œç²—ç•¥ç»“æ„â€ã€â€œç»†èŠ‚çº¹ç†â€ç­‰ |
| **Progressive Growingï¼ˆå¯é€‰ï¼‰** | ä»ä½åˆ†è¾¨ç‡é€æ­¥å¢é•¿åˆ°é«˜åˆ†è¾¨ç‡ï¼ˆStyleGAN v1ï¼‰ |
| **Truncation Trick** | æ§åˆ¶ç”Ÿæˆå›¾åƒå¤šæ ·æ€§ vs. è´¨é‡çš„å¹³è¡¡ |

---

## ğŸ› ï¸ äºŒã€ç®€åŒ–ç‰ˆ StyleGAN Generatorï¼ˆPyTorch å®ç°ï¼‰

```python
import torch
import torch.nn as nn
import torch.nn.functional as F

class MappingNetwork(nn.Module):
    def __init__(self, z_dim=512, w_dim=512, n_layers=8):
        super().__init__()
        layers = []
        for i in range(n_layers):
            layers.append(nn.Linear(z_dim if i == 0 else w_dim, w_dim))
            layers.append(nn.LeakyReLU(0.2))
        self.mapping = nn.Sequential(*layers)

    def forward(self, z):
        # z: (B, z_dim)
        return self.mapping(z)  # (B, w_dim)


class AdaIN(nn.Module):
    def __init__(self, channels, w_dim=512):
        super().__init__()
        self.instance_norm = nn.InstanceNorm2d(channels)
        self.style_scale = nn.Linear(w_dim, channels)
        self.style_bias = nn.Linear(w_dim, channels)

    def forward(self, x, w):
        # x: (B, C, H, W), w: (B, w_dim)
        x = self.instance_norm(x)
        scale = self.style_scale(w).unsqueeze(2).unsqueeze(3)  # (B, C, 1, 1)
        bias = self.style_bias(w).unsqueeze(2).unsqueeze(3)
        return x * (1 + scale) + bias


class StyleBlock(nn.Module):
    def __init__(self, in_channels, out_channels, w_dim=512):
        super().__init__()
        self.conv = nn.Conv2d(in_channels, out_channels, 3, padding=1)
        self.adaIN = AdaIN(out_channels, w_dim)
        self.noise_weight = nn.Parameter(torch.zeros(1))  # å™ªå£°æ³¨å…¥
        self.bias = nn.Parameter(torch.zeros(1, out_channels, 1, 1))

    def forward(self, x, w, noise=None):
        x = F.interpolate(x, scale_factor=2, mode='nearest')  # ä¸Šé‡‡æ ·
        x = self.conv(x)
        if noise is None:
            noise = torch.randn(x.shape[0], 1, x.shape[2], x.shape[3], device=x.device)
        x = x + self.noise_weight * noise
        x = x + self.bias
        x = F.leaky_relu(x, 0.2)
        x = self.adaIN(x, w)
        return x


class StyleGANGenerator(nn.Module):
    def __init__(self, z_dim=512, w_dim=512, img_channels=3, max_resolution=64):
        super().__init__()
        self.mapping = MappingNetwork(z_dim, w_dim)
        self.const_input = nn.Parameter(torch.randn(1, 512, 4, 4))
        self.initial_block = StyleBlock(512, 512, w_dim)
        
        # æ„å»ºå¤šå°ºåº¦ç”Ÿæˆå™¨
        self.blocks = nn.ModuleList()
        res = 8
        while res <= max_resolution:
            in_ch = 512 if res // 2 <= 16 else int(512 / (res // 16))
            out_ch = 512 if res <= 16 else int(512 / (res / 16))
            self.blocks.append(StyleBlock(in_ch, out_ch, w_dim))
            res *= 2

        self.to_rgb = nn.Conv2d(3, img_channels, 1)  # æœ€ç»ˆè¾“å‡ºå±‚

    def forward(self, z, noise=None):
        w = self.mapping(z)
        x = self.const_input.expand(z.shape[0], -1, -1, -1)
        x = self.initial_block(x, w, noise)

        for block in self.blocks:
            x = block(x, w, noise)
        
        x = self.to_rgb(x)
        return torch.tanh(x)  # è¾“å‡º [-1, 1]


# Discriminatorï¼ˆç®€åŒ–ç‰ˆï¼‰
class StyleGANDiscriminator(nn.Module):
    def __init__(self, img_channels=3, max_resolution=64):
        super().__init__()
        # ç®€åŒ–å®ç°ï¼šä½¿ç”¨æ ‡å‡† CNN
        self.features = nn.Sequential(
            nn.Conv2d(img_channels, 64, 4, 2, 1), nn.LeakyReLU(0.2),
            nn.Conv2d(64, 128, 4, 2, 1), nn.BatchNorm2d(128), nn.LeakyReLU(0.2),
            nn.Conv2d(128, 256, 4, 2, 1), nn.BatchNorm2d(256), nn.LeakyReLU(0.2),
            nn.AdaptiveAvgPool2d(4),
            nn.Flatten()
        )
        self.classifier = nn.Linear(256*4*4, 1)

    def forward(self, x):
        x = self.features(x)
        return self.classifier(x)
```

---

## ğŸ§ª ä¸‰ã€æµ‹è¯•ç”Ÿæˆå›¾åƒ

```python
# æµ‹è¯•ç”Ÿæˆ
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
G = StyleGANGenerator().to(device)
z = torch.randn(4, 512).to(device)
with torch.no_grad():
    fake_images = G(z)
print(fake_images.shape)  # [4, 3, 64, 64]
```

---

## ğŸš€ å››ã€ä½¿ç”¨é¢„è®­ç»ƒ StyleGANï¼ˆæ¨èåˆå­¦è€…ï¼‰

ä¸å…¶ä»é›¶è®­ç»ƒï¼Œä¸å¦‚ä½¿ç”¨å®˜æ–¹é¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œæ¨ç†ï¼š

### ä½¿ç”¨ `stylegan2-pytorch` åº“

```bash
pip install stylegan2-pytorch
```

æˆ–ä½¿ç”¨å®˜æ–¹é¡¹ç›®ï¼š
- GitHub: https://github.com/NVlabs/stylegan2-ada-pytorch

### ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹ï¼ˆå¦‚ FFHQ äººè„¸ï¼‰

```python
import torch
import numpy as np
from PIL import Image

# ä½¿ç”¨å®˜æ–¹ StyleGAN2-ADA é¢„è®­ç»ƒæ¨¡å‹
# å‚è€ƒ: https://github.com/NVlabs/stylegan2-ada-pytorch

# ç¤ºä¾‹ï¼šåŠ è½½é¢„è®­ç»ƒæƒé‡å¹¶ç”Ÿæˆå›¾åƒ
# æ³¨æ„ï¼šéœ€è¦ä¸‹è½½ .pkl æ¨¡å‹æ–‡ä»¶
```

å®˜æ–¹æä¾›äº†ä¸€ä¸ª `generate.py` è„šæœ¬ç”¨äºç”Ÿæˆå›¾åƒï¼š

```bash
python generate.py --outdir=out --seeds=1-10 --network=https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/models/ffhq-256.pkl
```

---

## ğŸ“ˆ äº”ã€è®­ç»ƒå»ºè®®

| é¡¹ç›® | å»ºè®® |
|------|------|
| æ•°æ®é›† | FFHQï¼ˆ70k é«˜æ¸…äººè„¸ï¼‰ã€CIFAR-10ï¼ˆå®éªŒç”¨ï¼‰ |
| åˆ†è¾¨ç‡ | ä» 64x64 å¼€å§‹ï¼Œå†å°è¯• 128x128 æˆ– 256x256 |
| Batch Size | å¤šå¡è®­ç»ƒæ—¶å¯ç”¨ 32~64ï¼Œå•å¡å¯ç”¨ 8~16 |
| ä¼˜åŒ–å™¨ | Adam, lr=0.002, Î²â‚=0.0, Î²â‚‚=0.99 |
| æ­£åˆ™åŒ– | è·¯å¾„é•¿åº¦æ­£åˆ™åŒ–ã€R1 æ¢¯åº¦æƒ©ç½š |
| è®­ç»ƒæ—¶é—´ | æ•°å¤©åˆ°æ•°å‘¨ï¼ˆå–å†³äº GPU å’Œæ•°æ®é›†ï¼‰ |

---

## ğŸ”— å…­ã€é‡è¦èµ„æº

1. **StyleGAN è®ºæ–‡**
    - [StyleGAN: A Style-Based Generator for High-Resolution Image Synthesis](https://arxiv.org/abs/1812.04948)
2. **StyleGAN2 è®ºæ–‡**
    - [Analyzing and Improving the Image Quality of StyleGAN](https://arxiv.org/abs/1912.04958)
3. **å®˜æ–¹ä»£ç ï¼ˆPyTorchï¼‰**
    - https://github.com/NVlabs/stylegan2-ada-pytorch
4. **ç¤¾åŒºå®ç°**
    - https://github.com/rosinality/stylegan2-pytorch
5. **äº¤äº’å¼å¯è§†åŒ–**
    - https://www.youtube.com/watch?v=kSLJriaOumA (AI Portraits)

---

## âœ… æ€»ç»“

- **ä»é›¶å®ç° StyleGAN éå¸¸å¤æ‚**ï¼Œå»ºè®®å…ˆç†è§£å…¶ç»“æ„ï¼Œå†å°è¯•ç®€åŒ–ç‰ˆã€‚
- **æ¨èä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œæ¨ç†å’Œç¼–è¾‘**ï¼ˆå¦‚é£æ ¼æ··åˆã€æ½œåœ¨ç©ºé—´æ’å€¼ï¼‰ã€‚
- **è®­ç»ƒéœ€å¼ºå¤§ GPUï¼ˆå¦‚ V100/A100ï¼‰å’Œå¤§é‡æ•°æ®**ï¼Œä¸é€‚åˆä¸ªäººè®¾å¤‡ä»å¤´è®­ç»ƒã€‚

---