ä½¿ç”¨ **ä¸»æˆåˆ†åˆ†æï¼ˆPrincipal Component Analysis, PCAï¼‰** è¿›è¡Œé™ç»´æ˜¯æ•°æ®é¢„å¤„ç†ä¸­çš„ä¸€ä¸ªå¸¸è§æ­¥éª¤ï¼Œå°¤å…¶é€‚ç”¨äºé«˜ç»´æ•°æ®çš„å¯è§†åŒ–å’Œç‰¹å¾æå–ã€‚PCA é€šè¿‡çº¿æ€§å˜æ¢å°†åŸå§‹æ•°æ®æŠ•å½±åˆ°ä¸€ä¸ªæ–°çš„åæ ‡ç³»ä¸­ï¼Œä½¿å¾—ç¬¬ä¸€ä¸»æˆåˆ†å…·æœ‰æœ€å¤§çš„æ–¹å·®ï¼Œç¬¬äºŒä¸»æˆåˆ†æ¬¡ä¹‹ï¼Œä»¥æ­¤ç±»æ¨ã€‚

åœ¨ Python ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ `scikit-learn` åº“æä¾›çš„ `PCA` ç±»æ¥å®ç°è¿™ä¸€åŠŸèƒ½ã€‚

---

## âœ… ä¸€ã€å®‰è£…ä¾èµ–

é¦–å…ˆç¡®ä¿ä½ å·²ç»å®‰è£…äº† `scikit-learn` å’Œ `matplotlib`ï¼ˆç”¨äºå¯è§†åŒ–ï¼‰ã€‚å¦‚æœæ²¡æœ‰å®‰è£…ï¼Œå¯ä»¥é€šè¿‡ä»¥ä¸‹å‘½ä»¤è¿›è¡Œå®‰è£…ï¼š

```bash
pip install scikit-learn matplotlib
```

---

## âœ… äºŒã€PCA ç¤ºä¾‹ä»£ç 

### ğŸ§ª ç¤ºä¾‹ï¼šå¯¹éšæœºç”Ÿæˆçš„æ•°æ®è¿›è¡Œé™ç»´

```python
from sklearn.decomposition import PCA
import numpy as np
import matplotlib.pyplot as plt

# Step 1: ç”Ÿæˆä¸€äº›äºŒç»´æ•°æ®
np.random.seed(0)
X = np.dot(np.random.rand(2, 2), np.random.randn(2, 100)).T  # 100ä¸ªæ ·æœ¬ï¼Œæ¯ä¸ªæ ·æœ¬2ç»´

# Step 2: ä½¿ç”¨PCAè¿›è¡Œé™ç»´
pca = PCA(n_components=2)  # å°†æ•°æ®é™è‡³2ç»´
X_reduced = pca.fit_transform(X)

print("åŸå§‹æ•°æ®å½¢çŠ¶:", X.shape)
print("é™ç»´åæ•°æ®å½¢çŠ¶:", X_reduced.shape)

# Step 3: è¾“å‡ºè§£é‡Šæ–¹å·®æ¯”ä¾‹
print("å„ä¸»æˆåˆ†è§£é‡Šæ–¹å·®æ¯”ä¾‹:", pca.explained_variance_ratio_)

# Step 4: å¯è§†åŒ–ç»“æœ
plt.figure(figsize=(8, 4))

# åŸå§‹æ•°æ®
plt.subplot(1, 2, 1)
plt.scatter(X[:, 0], X[:, 1])
plt.title("Original Data")

# é™ç»´åçš„æ•°æ®
plt.subplot(1, 2, 2)
plt.scatter(X_reduced[:, 0], X_reduced[:, 1])
plt.title("PCA Reduced Data (2D)")

plt.tight_layout()
plt.show()
```

### ğŸ” è¾“å‡ºç¤ºä¾‹ï¼š

- **è§£é‡Šæ–¹å·®æ¯”ä¾‹**ï¼šæ˜¾ç¤ºäº†æ¯ä¸ªä¸»æˆåˆ†æ‰€è§£é‡Šçš„æ–¹å·®æ¯”ä¾‹ï¼Œå¸®åŠ©ç†è§£é™ç»´çš„æ•ˆæœã€‚

```
å„ä¸»æˆåˆ†è§£é‡Šæ–¹å·®æ¯”ä¾‹: [0.95674... 0.04325...]
```

è¿™æ„å‘³ç€ç¬¬ä¸€ä¸ªä¸»æˆåˆ†è§£é‡Šäº†å¤§çº¦ 95% çš„æ–¹å·®ï¼Œè€Œç¬¬äºŒä¸ªä¸»æˆåˆ†åªè§£é‡Šäº†çº¦ 5% çš„æ–¹å·®ã€‚

---

## âœ… ä¸‰ã€ä½¿ç”¨PCAè¿›è¡Œæ›´é«˜ç»´åº¦æ•°æ®çš„é™ç»´

### ğŸ§ª ç¤ºä¾‹ï¼šå¯¹æ‰‹å†™æ•°å­—æ•°æ®é›†ï¼ˆMNISTï¼‰è¿›è¡Œé™ç»´å¹¶å¯è§†åŒ–

```python
from sklearn.decomposition import PCA
from sklearn.datasets import load_digits
import matplotlib.pyplot as plt

# Step 1: åŠ è½½æ‰‹å†™æ•°å­—æ•°æ®é›†
digits = load_digits()
X, y = digits.data, digits.target

# Step 2: ä½¿ç”¨PCAå°†æ•°æ®é™åˆ°2ç»´ä»¥ä¾¿äºå¯è§†åŒ–
pca = PCA(n_components=2)
X_reduced = pca.fit_transform(X)

# Step 3: è¾“å‡ºè§£é‡Šæ–¹å·®æ¯”ä¾‹
print("å„ä¸»æˆåˆ†è§£é‡Šæ–¹å·®æ¯”ä¾‹:", pca.explained_variance_ratio_)
print("æ€»è§£é‡Šæ–¹å·®æ¯”ä¾‹:", sum(pca.explained_variance_ratio_))

# Step 4: å¯è§†åŒ–é™ç»´åçš„æ•°æ®
plt.figure(figsize=(10, 6))
plt.scatter(X_reduced[:, 0], X_reduced[:, 1], c=y, edgecolor='none', alpha=0.5,
            cmap=plt.cm.get_cmap('nipy_spectral', 10))
plt.colorbar()
plt.title("PCA of Digits Dataset")
plt.show()
```

### ğŸ” è¾“å‡ºè¯´æ˜ï¼š

- æ¯ä¸ªç‚¹çš„é¢œè‰²ä»£è¡¨ä¸åŒçš„æ•°å­—ç±»åˆ«ã€‚
- ä½ å¯ä»¥çœ‹åˆ°ï¼Œå³ä½¿é™åˆ°äº†äºŒç»´ï¼Œä¸åŒç±»åˆ«çš„æ•°å­—ä»ç„¶æœ‰ä¸€å®šçš„èšç±»æ•ˆæœã€‚

---

## âœ… å››ã€é€‰æ‹©åˆé€‚çš„ä¸»æˆåˆ†æ•°ç›®

### æ–¹æ³• 1ï¼šåŸºäºè§£é‡Šæ–¹å·®æ¯”ä¾‹

```python
# é€‰æ‹©èƒ½å¤Ÿä¿ç•™è‡³å°‘95%æ–¹å·®çš„æœ€å°ä¸»æˆåˆ†æ•°ç›®
pca = PCA(n_components=0.95)  # è®¾ç½®ä¸ºä¿ç•™95%çš„æ–¹å·®
X_reduced = pca.fit_transform(X)

print("é€‰æ‹©äº†", pca.n_components_, "ä¸ªä¸»æˆåˆ†")
print("æ€»è§£é‡Šæ–¹å·®æ¯”ä¾‹:", sum(pca.explained_variance_ratio_))
```

### æ–¹æ³• 2ï¼šç´¯ç§¯è§£é‡Šæ–¹å·®å›¾

```python
pca = PCA().fit(X)

plt.plot(np.cumsum(pca.explained_variance_ratio_))
plt.xlabel('Number of Components')
plt.ylabel('Cumulative Explained Variance')
plt.title('Explained Variance vs Number of Components')
plt.grid(True)
plt.show()
```

---

## âœ… äº”ã€æ€»ç»“ä¸æ³¨æ„äº‹é¡¹

| æ­¥éª¤ | å†…å®¹ |
|------|------|
| æ•°æ®å‡†å¤‡ | ç¡®ä¿æ•°æ®å·²æ ‡å‡†åŒ–ï¼ˆå»ºè®®ä½¿ç”¨ `StandardScaler`ï¼‰ |
| PCAå¯¹è±¡åˆ›å»º | ä½¿ç”¨ `PCA(n_components=k)` åˆ›å»ºPCAå¯¹è±¡ |
| fit_transform | è°ƒç”¨ `.fit_transform()` æ–¹æ³•è¿›è¡Œé™ç»´ |
| å¯è§†åŒ– | ä½¿ç”¨æ•£ç‚¹å›¾ç­‰å·¥å…·å±•ç¤ºé™ç»´åçš„æ•°æ®åˆ†å¸ƒ |
| è§£é‡Šæ–¹å·®æ¯”ä¾‹ | æŸ¥çœ‹ `.explained_variance_ratio_` å±æ€§äº†è§£æ¯ä¸ªä¸»æˆåˆ†çš„é‡è¦æ€§ |

---